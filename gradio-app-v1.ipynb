{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d0201a-771d-4cee-a895-bf767f1ac121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import boto3\n",
    "import uuid\n",
    "import json\n",
    "from datetime import datetime\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0edf10a-fa68-4549-b4a1-e7be61e1a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"keyid\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"accesskey\"\n",
    "os.environ[\"AWS_REGION\"] = \"us-west-2\"\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b994b-1ce4-406f-aa21-1a221b75c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS DynamoDB setup\n",
    "dynamodb_resource = boto3.resource('dynamodb', region_name=\"us-west-2\")\n",
    "table = dynamodb_resource.Table('chat_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab1022-fa11-410d-b99e-0d94ccf64faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LLM model\n",
    "model_name = \"distilgpt2\"  # Example open-source model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=\"auto\")\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb03aa-e86d-4115-8eb8-7564e0eff2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save conversation history to DynamoDB\n",
    "def save_to_dynamodb(session_id, chat_history):\n",
    "    data = {\n",
    "        \"session_id\": session_id,\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"history\": json.dumps(chat_history),\n",
    "    }\n",
    "    print(\"Saving to DynamoDB:\", data)  # Debugging log\n",
    "    table.put_item(Item=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8870cb4-6af2-42a4-907a-3870949a3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query DynamoDB\n",
    "def get_from_dynamodb(session_id):\n",
    "    response = table.get_item(Key={\"session_id\": session_id})\n",
    "    if \"Item\" in response:\n",
    "        return json.loads(response[\"Item\"][\"history\"])\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11d777-654f-4b14-85a6-9ca8142ffb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a response from the LLM\n",
    "def chatbot(session_id, user_message, chat_history):\n",
    "    # Generate the LLM response\n",
    "    prompt = \" \".join([msg[\"content\"] for msg in chat_history if msg[\"role\"] == \"user\"]) + f\" {user_message}\"\n",
    "    llm_response = llm_pipeline(prompt, num_return_sequences=1, do_sample=True)[0][\"generated_text\"]\n",
    "\n",
    "    # Append user and LLM messages in the correct format\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": llm_response})\n",
    "\n",
    "    save_to_dynamodb(session_id, chat_history)\n",
    "    return chat_history, session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d1a56-8354-44ab-9ab1-fc942872d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio app\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Chatbot with LLM Response\")\n",
    "    session_id = gr.State(str(uuid.uuid4()))  # Generate unique session ID\n",
    "\n",
    "    # Single Chatbot component\n",
    "    chatbot_ui = gr.Chatbot(type='messages', label=\"Chatbot\")\n",
    "    user_input = gr.Textbox(label=\"Your Message\")\n",
    "    submit_button = gr.Button(\"Send\")\n",
    "\n",
    "    # Link the components\n",
    "    submit_button.click(chatbot, [session_id, user_input, chatbot_ui], [chatbot_ui, session_id])\n",
    "    \n",
    "    # Option to clear the chat\n",
    "    clear_button = gr.Button(\"Clear Chat\")\n",
    "    clear_button.click(lambda: ([], str(uuid.uuid4())), inputs=[], outputs=[chatbot_ui, session_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9beec40-4134-4b6a-bd8f-6a9f1f702653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch app with sharing enabled\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3fefea-1510-4c7d-ab42-3f2a65f71412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b220b75-4040-4fea-830d-1b92e37b08a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e9838-d2be-4544-ab5f-b85275680087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
